{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 1\n",
    "Here, I want to implement a very simple model. To do this, I'm not going to create very many features, just recode some of the variables that are categorical like district. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        % matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "from ipywidgets import widgets  \n",
    "from IPython.display import display\n",
    "\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "print sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data\n",
    "Now, I need to load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crimeData = pd.read_csv('train.csv')\n",
    "Categories = ['ARSON', 'ASSAULT', 'BAD CHECKS', 'BRIBERY', 'BURGLARY',\n",
    "              'DISORDERLY CONDUCT', 'DRIVING UNDER THE INFLUENCE',\n",
    "              'DRUG/NARCOTIC', 'DRUNKENNESS', 'EMBEZZLEMENT', 'EXTORTION',\n",
    "              'FAMILY OFFENSES', 'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING',\n",
    "              'KIDNAPPING', 'LARCENY/THEFT', 'LIQUOR LAWS', 'LOITERING',\n",
    "              'MISSING PERSON', 'NON-CRIMINAL', 'OTHER OFFENSES',\n",
    "              'PORNOGRAPHY/OBSCENE MAT', 'PROSTITUTION', 'RECOVERED VEHICLE',\n",
    "              'ROBBERY', 'RUNAWAY', 'SECONDARY CODES', 'SEX OFFENSES FORCIBLE',\n",
    "              'SEX OFFENSES NON FORCIBLE', 'STOLEN PROPERTY', 'SUICIDE',\n",
    "              'SUSPICIOUS OCC', 'TREA', 'TRESPASS', 'VANDALISM', 'VEHICLE THEFT',\n",
    "              'WARRANTS', 'WEAPON LAWS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for recoding data\n",
    "Here are the helper functions for recoding data. We'll add more as we create some new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recodeData(df, isTrain = False):\n",
    "    '''This function takes in the dataframe that we get from loading in the \n",
    "    SF crime data and returns a re-coded dataframe that has all the \n",
    "    additional features we want to add and the categorical features recoded \n",
    "    and cleaned.\n",
    "    '''\n",
    "\n",
    "    #since the modifications are done in-place we don't return the dataframe. \n",
    "    #we do, however, return the list of all the columns we added.\n",
    "    newLatLon = removeOutlierLatLon(df)\n",
    "    newDate = recodeDates(df)\n",
    "    newDistrict = recodePoliceDistricts(df)\n",
    "    newAddress = recodeAddresses(df)\n",
    "\n",
    "    \n",
    "    addedColumns = [] \n",
    "    addedColumns += newDate\n",
    "    addedColumns += newDistrict \n",
    "    addedColumns += newAddress\n",
    "    addedColumns += newLatLon\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    if (isTrain):\n",
    "        newCategory = recodeCategories(df)\n",
    "        addedColumns += newCategory\n",
    "        try: #prevents error if the coumns have already been removed or we are processing test data\n",
    "            columnsToDrop = ['Descript', 'Resolution']\n",
    "            df.drop(columnsToDrop, axis=1, inplace=True)\n",
    "        except:\n",
    "            print \"already recoded or using test data\"\n",
    "         \n",
    "\n",
    "    return df, addedColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodeDates(df):\n",
    "    '''This function takes in a dataframe and recodes the date field into \n",
    "    useable values. Here, we also recode the day of week.'''\n",
    "    #Recode the dates column to year, month, day and hour columns\n",
    "    df['DateTime'] = df['Dates'].apply(\n",
    "        lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    df['Year'] = df['DateTime'].apply(lambda x: x.year)\n",
    "    df['Month'] = df['DateTime'].apply(lambda x: x.month)\n",
    "    df['Day'] = df['DateTime'].apply(lambda x: x.day)\n",
    "    df['Hour'] = df['DateTime'].apply(lambda x: x.hour)\n",
    "    df['Minute'] = df['DateTime'].apply(lambda x: x.minute)\n",
    "    df['DayOfWeekRecode'] = df['DateTime'].apply(lambda x: x.weekday())\n",
    "    #df['MinuteOfWeek'] = df['DateTime'].apply(lambda x: x.weekday()*24*60 + x.hour*60 + x.minute)\n",
    "\n",
    "    return ['Year', 'Month', 'Day', 'Hour', 'Minute', 'DayOfWeekRecode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodePoliceDistricts(df):\n",
    "    '''This function recodes the police district to a one-hot encoding \n",
    "    scheme.'''\n",
    "    districts = df['PdDistrict'].unique().tolist()\n",
    "    newColumns = []\n",
    "    for district in districts:\n",
    "        newColumns.append('District' + district)\n",
    "        df['District' + district] = df['PdDistrict'].apply(\n",
    "            lambda x: int(x == district))\n",
    "\n",
    "    return newColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recodeAddresses(df):\n",
    "    '''This function will attempt to create some features related to the address field in the database. To do this, \n",
    "    first, we need to split up the address field into two different address fields'''\n",
    "    \n",
    "    #If there are two addresss, split fields. Also extract the block number\n",
    "    df['Address1'] = df['Address'].apply(lambda x: re.sub(r'^\\d+ Block of ','',x.split(\" / \")[0]))\n",
    "    df['Address2'] = df['Address'].apply(lambda x: (x.split(\" / \")[1]) if (len(x.split(\" / \")) > 1) else None)\n",
    "    df['BlockNumber'] = df['Address'].apply(lambda x: int(re.findall(r'^\\d+',x)[0]) if (len(re.findall(r'^\\d+',x)) > 0) else None )\n",
    "    df['BlockNumber'] = df['BlockNumber'].fillna(-1)\n",
    "    \n",
    "    #Also add the \"did the crime occur on a street corner field?\"\n",
    "    df['StreetCornerFlag'] = df['Address'].apply(lambda x: len(x.split(\" / \")) > 1)\n",
    "    \n",
    "    return ['StreetCornerFlag', 'BlockNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def removeOutlierLatLon(df):\n",
    "    '''This function will attempt remove outlier Latitudes and Longitudes'''\n",
    "    df.loc[df.X > -121, 'X'] = df.loc[(df.X > -121)].apply(lambda row: df.X[df[\"PdDistrict\"] == row['PdDistrict']].median(), axis=1)\n",
    "    df.loc[df.Y > 38, 'Y'] = df.loc[(df.Y > 38)].apply(lambda row: df.Y[df[\"PdDistrict\"] == row['PdDistrict']].median(), axis=1)\n",
    "\n",
    "    return ['X', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodeCategories(df):\n",
    "    '''This function will attempt remove outlier Latitudes and Longitudes'''\n",
    "    #if 'Category' in df.columns:\n",
    "    df['CategoryRecode'] = df.Category.apply(lambda x: Categories.index(x))\n",
    "        \n",
    "    return ['CategoryRecode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding Columns\n",
    "Here, we want to do some recoding of the columns. To do this, we're going to use our handy-dandy helper functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crimeData, addedColumns = recodeData(\n",
    "    crimeData, isTrain = True)\n",
    "crimeData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Iteration 1\n",
    "Now that I've done some recoding, I'm going to create my model. To do this, I'm going to do a random forest classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columnsToUse = addedColumns\n",
    "\n",
    "columnsToUse = ['X','Y', 'Year', 'Month', 'Hour', 'Minute',\n",
    "       'DayOfWeekRecode', 'DistrictNORTHERN', 'DistrictPARK',\n",
    "       'DistrictINGLESIDE', 'DistrictBAYVIEW', 'DistrictRICHMOND',\n",
    "       'DistrictCENTRAL', 'DistrictTARAVAL', 'DistrictTENDERLOIN',\n",
    "       'DistrictMISSION', 'DistrictSOUTHERN', 'StreetCornerFlag']\n",
    "\n",
    "X = crimeData[columnsToUse]\n",
    "y = crimeData['CategoryRecode']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth = 20, random_state=1, n_jobs = 1, verbose=2)\n",
    "\n",
    "k_folds = StratifiedShuffleSplit(y, 3, test_size=0.5, random_state=0)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for k, (train, test) in enumerate(k_folds):\n",
    "    clf.fit(X.iloc[train], y.iloc[train])\n",
    "    probs = clf.predict_proba(X.iloc[test])\n",
    "    score = log_loss(y.iloc[test].values, probs)\n",
    "    print score\n",
    "    scores.append(score)\n",
    "    \n",
    "print(scores)\n",
    "print(\"Average: \" + str(np.average(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(clf, predictors, path='my_submission.csv'):\n",
    "    '''This function will take in a trained model, a list of predictors, and an optional \n",
    "    filepath and create a submissision file for us.'''\n",
    "   \n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    test_data, newColumns = recodeData(test_data)\n",
    "    \n",
    "    #clf.fit(trainX[predictors], trainY)\n",
    "    predictions = clf.predict_proba(test_data[predictors])\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'Id': test_data.Id\n",
    "    })\n",
    "    \n",
    "    for i in range(predictions.shape[1]):\n",
    "        submission[Categories[i]] = predictions[:,i]\n",
    "    submission.to_csv(path, index=False)\n",
    "\n",
    "    print(\" -- Wrote submission to file {}.\".format(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X, y)\n",
    "print \"model fitted with all data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_submission(clf, columnsToUse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Score: \t\n",
    "2.44156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
