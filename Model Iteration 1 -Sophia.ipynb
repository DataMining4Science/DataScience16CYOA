{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 1\n",
    "Here, I want to implement a very simple model. To do this, I'm not going to create very many features, just recode some of the variables that are categorical like district. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import shapefile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "from ipywidgets import widgets  \n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data\n",
    "Now, I need to load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crimeData = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for recoding data\n",
    "Here are the helper functions for recoding data. We'll add more as we create some new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodeData(df, isTrain = False):\n",
    "    '''This function takes in the dataframe that we get from loading in the \n",
    "    SF crime data and returns a re-coded dataframe that has all the \n",
    "    additional features we want to add and the categorical features recoded \n",
    "    and cleaned.\n",
    "    '''\n",
    "\n",
    "    #since the modifications are done in-place we don't return the dataframe. \n",
    "    #we do, however, return the list of all the columns we added.\n",
    "    newDate = recodeDates(df)\n",
    "    newDistrict = recodePoliceDistricts(df)\n",
    "    \n",
    "    addedColumns = [] \n",
    "    addedColumns += newDate\n",
    "    addedColumns += newDistrict \n",
    "\n",
    "    if (isTrain):\n",
    "        try: #prevents error if the coumns have already been removed\n",
    "            columnsToDrop = ['Descript', 'Resolution']\n",
    "            df.drop(columnsToDrop, axis=1, inplace=True)\n",
    "        except:\n",
    "            print \"already recoded\"\n",
    "\n",
    "    return df, addedColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodeDates(df):\n",
    "    '''This function takes in a dataframe and recodes the date field into \n",
    "    useable values. Here, we also recode the day of week.'''\n",
    "    #Recode the dates column to year, month, day and hour columns\n",
    "    df['DateTime'] = df['Dates'].apply(\n",
    "        lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    df['Year'] = df['DateTime'].apply(lambda x: x.year)\n",
    "    df['Month'] = df['DateTime'].apply(lambda x: x.month)\n",
    "    df['Day'] = df['DateTime'].apply(lambda x: x.day)\n",
    "    df['Hour'] = df['DateTime'].apply(lambda x: x.hour)\n",
    "    df['Minute'] = df['DateTime'].apply(lambda x: x.minute)\n",
    "    df['DayOfWeekRecode'] = df['DateTime'].apply(lambda x: x.weekday())\n",
    "    df['MinuteOfWeek'] = df['DateTime'].apply(lambda x: x.weekday()*24*60 + x.hour*60 + x.minute)\n",
    "\n",
    "    return ['Year', 'Month', 'Day', 'Hour', 'Minute', 'DayOfWeekRecode', 'MinuteOfWeek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodePoliceDistricts(df):\n",
    "    '''This function recodes the police district to a one-hot encoding \n",
    "    scheme.'''\n",
    "    districts = df['PdDistrict'].unique().tolist()\n",
    "    newColumns = []\n",
    "    for district in districts:\n",
    "        newColumns.append('District' + district)\n",
    "        df['District' + district] = df['PdDistrict'].apply(\n",
    "            lambda x: int(x == district))\n",
    "\n",
    "    return newColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding Columns\n",
    "Here, I want to do some recoding of the columns. To do this, I'm going to use our handy-dandy helper function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crimeData, addedColumns = recodeData(\n",
    "    crimeData, isTrain = True)\n",
    "crimeData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Iteration 1\n",
    "Now that I've done some recoding, I'm going to create my model. To do this, I'm going to do a random forest classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columnsToUse = addedColumns + ['X','Y']\n",
    "\n",
    "X = crimeData[columnsToUse]\n",
    "y = crimeData['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "probs = clf.predict_proba(X_test)\n",
    "\n",
    "score = log_loss(y_test, probs)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission function came from [this script](https://www.kaggle.com/shifanmao/sf-crime/random-forest-2/code)\n",
    "\n",
    "We modified this slightly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(clf, path='my_submission.csv'):\n",
    "    '''This function will take in a model and a an optional \n",
    "    filepath and create a submissision file for us.'''\n",
    "   \n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    test_data, columnsToUse = recodeData(test_data)\n",
    "    \n",
    "    X_test_data = test_data[columnsToUse]\n",
    "    ids = test_data['Id']\n",
    "    \n",
    "    #Predict the probabilities of each crime. \n",
    "    y_prob = clf.predict_proba(X_test_data)\n",
    "\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(\"ID,\")\n",
    "        f.write(','.join(clf.classes_))\n",
    "        f.write('\\n')\n",
    "\n",
    "        for id, probs in zip(ids, y_prob):\n",
    "#            probas = ','.join([id] + list(map(str, probs.tolist())))\n",
    "            probas = ','.join([str(id)] + map(str,[\"%.2f\" % elem for elem in list(map(float,probs.tolist()))]))\n",
    "#            probas = ','.join(list(map(str, probs.tolist())))\n",
    "            f.write(probas)\n",
    "            f.write('\\n')\n",
    "    print(\" -- Wrote submission to file {}.\".format(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_submission(clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
