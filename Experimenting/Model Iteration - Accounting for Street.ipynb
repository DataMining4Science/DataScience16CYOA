{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 1\n",
    "Here, I want to implement a very simple model. To do this, I'm not going to create very many features, just recode some of the variables that are categorical like district. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "from ipywidgets import widgets  \n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data\n",
    "Now, I need to load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "readData = pd.read_csv('train.csv')\n",
    "Categories = ['ARSON', 'ASSAULT', 'BAD CHECKS', 'BRIBERY', 'BURGLARY',\n",
    "              'DISORDERLY CONDUCT', 'DRIVING UNDER THE INFLUENCE',\n",
    "              'DRUG/NARCOTIC', 'DRUNKENNESS', 'EMBEZZLEMENT', 'EXTORTION',\n",
    "              'FAMILY OFFENSES', 'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING',\n",
    "              'KIDNAPPING', 'LARCENY/THEFT', 'LIQUOR LAWS', 'LOITERING',\n",
    "              'MISSING PERSON', 'NON-CRIMINAL', 'OTHER OFFENSES',\n",
    "              'PORNOGRAPHY/OBSCENE MAT', 'PROSTITUTION', 'RECOVERED VEHICLE',\n",
    "              'ROBBERY', 'RUNAWAY', 'SECONDARY CODES', 'SEX OFFENSES FORCIBLE',\n",
    "              'SEX OFFENSES NON FORCIBLE', 'STOLEN PROPERTY', 'SUICIDE',\n",
    "              'SUSPICIOUS OCC', 'TREA', 'TRESPASS', 'VANDALISM', 'VEHICLE THEFT',\n",
    "              'WARRANTS', 'WEAPON LAWS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for recoding data\n",
    "Here are the helper functions for recoding data. We'll add more as we create some new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def recodeData(df, isTrain = False):\n",
    "    '''This function takes in the dataframe that we get from loading in the \n",
    "    SF crime data and returns a re-coded dataframe that has all the \n",
    "    additional features we want to add and the categorical features recoded \n",
    "    and cleaned.\n",
    "    '''\n",
    "\n",
    "    #since the modifications are done in-place we don't return the dataframe. \n",
    "    #we do, however, return the list of all the columns we added.\n",
    "    newLatLon = removeOutlierLatLon(df)\n",
    "    newDate = recodeDates(df)\n",
    "    newDistrict = recodePoliceDistricts(df)\n",
    "    newAddress = recodeAddresses(df)\n",
    "\n",
    "    \n",
    "    addedColumns = [] \n",
    "    addedColumns += newDate\n",
    "    addedColumns += newDistrict \n",
    "    addedColumns += newAddress\n",
    "    addedColumns += newLatLon\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    if (isTrain):\n",
    "        newCategory = recodeCategories(df)\n",
    "#         addedColumns += newCategory\n",
    "        try: #prevents error if the coumns have already been removed or we are processing test data\n",
    "            columnsToDrop = ['Descript', 'Resolution']\n",
    "            df.drop(columnsToDrop, axis=1, inplace=True)\n",
    "        except:\n",
    "            print \"already recoded\"\n",
    "         \n",
    "\n",
    "    return df, addedColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def recodeDates(df):\n",
    "    '''This function takes in a dataframe and recodes the date field into \n",
    "    useable values. Here, we also recode the day of week.'''\n",
    "    print(\"Recoding Dates\")\n",
    "    #Recode the dates column to year, month, day and hour columns\n",
    "    df['DateTime'] = df['Dates'].apply(\n",
    "        lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    df['Year'] = df['DateTime'].apply(lambda x: x.year)\n",
    "    df['Month'] = df['DateTime'].apply(lambda x: x.month)\n",
    "    df['Day'] = df['DateTime'].apply(lambda x: x.day)\n",
    "    df['Hour'] = df['DateTime'].apply(lambda x: x.hour)\n",
    "    df['Minute'] = df['DateTime'].apply(lambda x: x.minute)\n",
    "    df['DayOfWeekRecode'] = df['DateTime'].apply(lambda x: x.weekday())\n",
    "    #df['MinuteOfWeek'] = df['DateTime'].apply(lambda x: x.weekday()*24*60 + x.hour*60 + x.minute)\n",
    "\n",
    "    return ['Year', 'Month', 'Day', 'Hour', 'Minute', 'DayOfWeekRecode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def recodePoliceDistricts(df):\n",
    "    '''This function recodes the police district to a one-hot encoding \n",
    "    scheme.'''\n",
    "    print (\"Recoding Districts\")\n",
    "    districts = df['PdDistrict'].unique().tolist()\n",
    "    newColumns = []\n",
    "    for district in districts:\n",
    "        newColumns.append('District' + district)\n",
    "        df['District' + district] = df['PdDistrict'] == district\n",
    "\n",
    "    return newColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def recodeAddresses(df):\n",
    "    '''This function will attempt to create some features related to the address field in the database. To do this, \n",
    "    first, we need to split up the address field into two different address fields'''\n",
    "    \n",
    "    print (\"Recoding Addresses\")\n",
    "    #If there are two addresss, split fields. Also extract the block number\n",
    "    df['Address1'] = df['Address'].apply(lambda x: re.sub(r'^\\d+ Block of ','',x.split(\" / \")[0]))\n",
    "    df['Address2'] = df['Address'].apply(lambda x: (x.split(\" / \")[1]) if (len(x.split(\" / \")) > 1) else '')\n",
    "    \n",
    "    popularStreets = {'ARSON': ['FITCH ST', 'FOLSOM ST', 'MISSION ST', 'BRYANT ST', 'POLK ST', 'MARKET ST'],\n",
    "                         'ASSAULT': ['BRYANT ST', 'MARKET ST', 'MISSION ST', 'JONES ST'],\n",
    "                         'BAD CHECKS': ['BRYANT ST', '2ND ST', 'MARKET ST', 'MISSION ST', '16TH ST'],\n",
    "                         'BRIBERY': ['6TH ST', 'BRYANT ST', 'MISSION ST', 'EDDY ST'],\n",
    "                         'BURGLARY': ['MISSION ST', 'FULTON ST', 'HARRISON ST', 'MARKET ST', 'POLK ST', 'BRYANT ST'],\n",
    "                         'DISORDERLY CONDUCT': ['CAPP ST', '16TH ST', '17TH ST', 'SHOTWELL ST', 'ELLIS ST', 'HAIGHT ST'],\n",
    "                         'DRIVING UNDER THE INFLUENCE': ['MARKET ST', 'FOLSOM ST', 'GEARY BL', 'MISSION ST'],\n",
    "                         'DRUG/NARCOTIC': ['MISSION ST', 'JONES ST', 'TAYLOR ST', 'TURK ST', 'MARKET ST', 'LEAVENWORTH ST'],\n",
    "                         'DRUNKENNESS': ['COLE ST', 'MARKET ST', 'MISSION ST', 'HAIGHT ST'],\n",
    "                         'EMBEZZLEMENT': ['BRYANT ST', 'OFARRELL ST', '4TH ST', 'MARKET ST', 'MISSION ST'],\n",
    "                         'EXTORTION': ['MISSION ST', 'LYON ST', 'GENEVA AV', 'BRYANT ST', 'OFARRELL ST', 'GEARY BL'],\n",
    "                         'FAMILY OFFENSES': ['MARKET ST', 'JONES ST', 'EDDY ST', 'MISSION ST', 'POTRERO AV'],\n",
    "                         'FORGERY/COUNTERFEITING': ['BRYANT ST', 'MARKET ST', 'MISSION ST', 'JONES ST'],\n",
    "                         'FRAUD': ['MARKET ST', 'BRYANT ST', 'MISSION ST', 'POWELL ST'],\n",
    "                         'GAMBLING': ['MISSION ST', 'KEARNY ST', '3RD ST', 'JEFFERSON ST', 'QUESADA AV', 'POWELL ST'],\n",
    "                         'KIDNAPPING': ['MARKET ST', 'TURK ST', 'BRYANT ST', 'MISSION ST', '16TH ST'],\n",
    "                         'LARCENY/THEFT': ['HARRISON ST', 'BRYANT ST', 'MARKET ST', 'MISSION ST'],\n",
    "                         'LIQUOR LAWS': ['3RD ST', '24TH ST', 'MISSION ST', 'COLE ST'],\n",
    "                         'LOITERING': ['HARRISON ST', 'SOUTH VAN NESS AV', 'MISSION ST', '13TH ST'],\n",
    "                         'MISSING PERSON': ['PHELPS ST', 'MISSION ST', 'HARRISON ST', 'MARKET ST', 'POTRERO AV', 'BRYANT ST'],\n",
    "                         'NON-CRIMINAL': ['MARKET ST', 'BRYANT ST', 'MISSION ST', 'POWELL ST'],\n",
    "                         'OTHER OFFENSES': ['BRYANT ST', 'MARKET ST', 'MISSION ST', 'JONES ST'],\n",
    "                         'PORNOGRAPHY/OBSCENE MAT': ['16TH ST', '18TH ST', 'LARKIN ST', 'TREAT AV', '10TH AV', '5TH ST'],\n",
    "                         'PROSTITUTION': ['17TH ST', 'LARKIN ST', '19TH ST', 'HYDE ST', 'SHOTWELL ST'],\n",
    "                         'RECOVERED VEHICLE': ['HARRISON ST', 'ELLIS ST', 'ALEMANY BL', 'LARKIN ST', 'MISSION ST'],\n",
    "                         'ROBBERY': ['BRYANT ST', 'MARKET ST', 'MISSION ST', 'JONES ST'],\n",
    "                         'RUNAWAY': ['MISSION ST', '12TH AV', 'CAPITOL AV', 'POTRERO AV', 'MARKET ST', 'PAGE ST'],\n",
    "                         'SECONDARY CODES': ['3RD ST', 'MARKET ST', 'BRYANT ST', 'MISSION ST'],\n",
    "                         'SEX OFFENSES FORCIBLE': ['MARKET ST', 'POLK ST', 'BRYANT ST', 'MISSION ST'],\n",
    "                         'SEX OFFENSES NON FORCIBLE': ['18TH ST', '3RD ST', 'BRYANT ST', '17TH ST', 'POTRERO AV', '11TH AV'],\n",
    "                         'STOLEN PROPERTY': ['BRYANT ST', 'POLK ST', 'MARKET ST', 'MISSION ST'],\n",
    "                         'SUICIDE': ['BRYANT ST', 'BUSH ST', '7TH ST', 'POTRERO AV', '24TH AV', 'GGBRIDGE HY'],\n",
    "                         'SUSPICIOUS OCC': ['MARKET ST', 'BRYANT ST', 'MISSION ST', 'TAYLOR ST'],\n",
    "                         'TREA': ['20TH ST', 'ARMSTRONG AV', 'CASTRO ST'],\n",
    "                         'TRESPASS': ['HARRISON ST', 'BRYANT ST', 'MARKET ST', 'MISSION ST', 'POTRERO AV'],\n",
    "                         'VANDALISM': ['HARRISON ST', 'MARKET ST', 'FOLSOM ST', 'BRYANT ST', 'MISSION ST'],\n",
    "                         'VEHICLE THEFT': ['3RD ST', 'HARRISON ST', 'FOLSOM ST', 'MISSION ST'],\n",
    "                         'WARRANTS': ['BRYANT ST', 'MARKET ST', 'MISSION ST', 'JONES ST'],\n",
    "                         'WEAPON LAWS': ['TURK ST', 'MARKET ST', 'MISSION ST', 'JONES ST']}\n",
    "\n",
    "    \n",
    "    addedCols = ['StreetCornerFlag', 'BlockNumber']\n",
    "    \n",
    "    for category in Categories:\n",
    "        addedCols.append('CommonStreet' + category)\n",
    "        #df['CommonStreet' + category] = df.apply(lambda x: (x['Address1'] in popularStreets[category] or x['Address2'] in popularStreets[category]), axis=1)\n",
    "        df['CommonStreet' + category] = (df['Address1'].isin(popularStreets[category])) | (df['Address2'].isin(popularStreets[category]))\n",
    "    \n",
    "    #     streets = set(df['Address1'].unique().tolist() + df['Address2'].unique().tolist())\n",
    "    #     for street in streets:\n",
    "    #         df['OnStreet' + street] = df.apply(lambda x: (x['Address1'] == street or x['Address2'] == street), axis=1)\n",
    "\n",
    "    #Also, try getting dummies for the addresses?\n",
    "    \n",
    "    \n",
    "    df['BlockNumber'] = df['Address'].apply(lambda x: int(re.findall(r'^\\d+',x)[0]) if (len(re.findall(r'^\\d+',x)) > 0) else None )\n",
    "    df['BlockNumber'] = df['BlockNumber'].fillna(-1)\n",
    "    \n",
    "    #Also add the \"did the crime occur on a street corner field?\"\n",
    "    df['StreetCornerFlag'] = df['Address'].apply(lambda x: len(x.split(\" / \")) > 1)\n",
    "    return addedCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def removeOutlierLatLon(df):\n",
    "    '''This function will attempt remove outlier Latitudes and Longitudes'''\n",
    "    print(\"Removing LatLong Outliers and Binning Lat and Long\")\n",
    "    df.loc[df.X > -121, 'X'] = df.loc[(df.X > -121)].apply(lambda row: df.X[df[\"PdDistrict\"] == row['PdDistrict']].median(), axis=1)\n",
    "    df.loc[df.Y > 38, 'Y'] = df.loc[(df.Y > 38)].apply(lambda row: df.Y[df[\"PdDistrict\"] == row['PdDistrict']].median(), axis=1)\n",
    "    \n",
    "#     xs = [df['X'].min(), df['X'].max()]\n",
    "#     ys = [df['Y'].min(), df['Y'].max()]\n",
    "#     xbins = 20\n",
    "#     ybins = 20\n",
    "    \n",
    "#     xBins = np.linspace(xs[0],xs[1],xbins+1 )\n",
    "#     yBins = np.linspace(ys[0],ys[1],ybins+1 )\n",
    "#     #Handle weird outliers\n",
    "#     xBins = np.concatenate(([xBins[0] -1], xBins, [xBins[-1]+ 1]))\n",
    "#     yBins = np.concatenate(([yBins[0] -1], yBins, [yBins[-1]+ 1]))\n",
    "#     print (xBins, yBins)\n",
    "\n",
    "    \n",
    "#     df['XBins'] = pd.cut(df['X'], xBins, labels=range(len(xBins)-1))\n",
    "#     df['YBins'] = pd.cut(df['Y'], yBins, labels=range(len(yBins)-1))\n",
    "#     return ['XBins', 'YBins']\n",
    "    return ['X', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def recodeCategories(df):\n",
    "    '''This function will recode the crime category to the appropriate number'''\n",
    "    print('Recoding categories')\n",
    "    #if 'Category' in df.columns:\n",
    "    df['CategoryRecode'] = df.Category.apply(lambda x: Categories.index(x))\n",
    "        \n",
    "    return ['CategoryRecode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding Columns\n",
    "Here, we want to do some recoding of the columns. To do this, we're going to use our handy-dandy helper functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crimeData, addedColumns = recodeData(\n",
    "    readData, isTrain = True)\n",
    "crimeData.describe()\n",
    "# crimeData[crimeData[['XBins', 'YBins']].isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Iteration 1\n",
    "Now that I've done some recoding, I'm going to create my model. To do this, I'm going to do a random forest classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columnsToUse = addedColumns\n",
    "\n",
    "# columnsToUse = ['X','Y', 'Year', 'Month', 'Hour', 'Minute',\n",
    "#        'DayOfWeekRecode', 'DistrictNORTHERN', 'DistrictPARK',\n",
    "#        'DistrictINGLESIDE', 'DistrictBAYVIEW', 'DistrictRICHMOND',\n",
    "#        'DistrictCENTRAL', 'DistrictTARAVAL', 'DistrictTENDERLOIN',\n",
    "#        'DistrictMISSION', 'DistrictSOUTHERN', 'StreetCornerFlag', 'BlockNumber']\n",
    "\n",
    "X = crimeData[columnsToUse]\n",
    "y = crimeData['CategoryRecode']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=30, max_depth = 8, max_leaf_nodes = 100, random_state=1, verbose=2)\n",
    "\n",
    "k_folds = StratifiedShuffleSplit(y, 3, test_size=0.5, random_state=0)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for k, (train, test) in enumerate(k_folds):\n",
    "    clf.fit(X.iloc[train], y.iloc[train])\n",
    "    probs = clf.predict_proba(X.iloc[test])\n",
    "    score = log_loss(y.iloc[test], probs)\n",
    "    print score\n",
    "    scores.append(score)\n",
    "    \n",
    "print(scores)\n",
    "print(\"Average: \" + str(np.average(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "addedColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_submission(clf, predictors, path='my_submission.csv'):\n",
    "    '''This function will take in a trained model, a list of predictors, and an optional \n",
    "    filepath and create a submissision file for us.'''\n",
    "   \n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    test_data, newColumns = recodeData(test_data)\n",
    "    \n",
    "    #clf.fit(trainX[predictors], trainY)\n",
    "    predictions = clf.predict_proba(test_data[newColumns])\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'Id': test_data.Id\n",
    "    })\n",
    "    \n",
    "    for i in range(predictions.shape[1]):\n",
    "        submission[Categories[i]] = predictions[:,i]\n",
    "    submission.to_csv(path, index=False)\n",
    "\n",
    "    print(\" -- Wrote submission to file {}.\".format(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X, y)\n",
    "print \"model fitted with all data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_submission(clf, columnsToUse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Score: \t\n",
    "2.44156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so what I'm going to do here, is to go category by category and make human decisions about what constitutes as a top contender for streets based on each crime category. Then, I'll create a dictionary of what I think are the top streets for this to happen on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countsByStreet = crimeData.groupby(['Category','Address1']).count().reset_index()\n",
    "countsByStreet2 = crimeData.groupby(['Category','Address2']).count().reset_index()\n",
    "\n",
    "mostPopStreetsNum = 3\n",
    "howManyTopStreets = 5\n",
    "#Get the most popular streets for crime:\n",
    "streetCounts =  crimeData.groupby(['Address1']).count().reset_index().sort_values(by =['Dates'], ascending=[0]).groupby('Address1').head(mostPopStreetsNum)\n",
    "popStreets = streetCounts.head(mostPopStreetsNum)['Address1'].tolist()\n",
    "\n",
    "\n",
    "streetCounts2 =  crimeData[crimeData.Address2 != ''].groupby(['Address2']).count().reset_index().sort_values(by =['Dates'], ascending=[0]).groupby('Address2').head(mostPopStreetsNum)\n",
    "popStreets2 = streetCounts2.head(mostPopStreetsNum)['Address2'].tolist()\n",
    "\n",
    "popStreets = list(set(popStreets + popStreets2))\n",
    "\n",
    "popularCategories = {}\n",
    "for category in Categories:\n",
    "    categoryCounts = countsByStreet[countsByStreet.Category == category]\n",
    "    categoryCounts2 = countsByStreet2[countsByStreet2.Category == category]\n",
    "    categoryCounts2 = categoryCounts2[categoryCounts2.Address2 != '']\n",
    "    \n",
    "    maxCountsByStreet = categoryCounts.sort_values(by =['Category', 'Dates'], ascending=[1,0]).groupby('Category').head(howManyTopStreets)\n",
    "    maxCountsByStreet2 = categoryCounts2.sort_values(by =['Category', 'Dates'], ascending=[1,0]).groupby('Category').head(howManyTopStreets)\n",
    "    \n",
    "    address1Streets = [street for street in maxCountsByStreet['Address1'].tolist() if not(street in popStreets)]\n",
    "    address2Streets = [street for street in maxCountsByStreet2['Address2'].tolist() if not(street not in popStreets)]\n",
    "    \n",
    "    popularCategories[category] = list(set(address1Streets + address2Streets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "popularCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popStreets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe, it'll be interesting to divide the lat longs into a grid, and have that be a feature. This way the model has to split less on lat long?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xs = [crimeData['X'].min(), crimeData['X'].max()]\n",
    "ys = [crimeData['Y'].min(), crimeData['Y'].max()]\n",
    "xbins = 2\n",
    "ybins = 2\n",
    "xBins = np.linspace(xs[0],xs[1],xbins+1 )\n",
    "yBins = np.linspace(ys[0],ys[1],ybins+1 )\n",
    "xs,xBins, ys, yBins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crimeData['XBins'] = pd.cut(crimeData['X'], xBins, labels=range(1,len(xBins)))\n",
    "crimeData['YBins'] = pd.cut(crimeData['Y'], yBins, labels=range(1,len(yBins)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
